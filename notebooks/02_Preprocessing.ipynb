{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c8d2e59-99dc-4c5c-b978-bd23ea847b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test files found: ['islamabad_complete_data_july_to_dec_2024.csv', 'karachi_complete_data_july_to_dec_2024.csv', 'lahore_complete_data_july_to_dec_2024.csv', 'peshawar_complete_data_july_to_dec_2024.csv', 'quetta_complete_data_july_to_dec_2024.csv']\n",
      "Shape of merged test dataset: (21792, 18)\n",
      "\n",
      "Missing values per column:\n",
      "datetime                0\n",
      "main_aqi                0\n",
      "components_co           0\n",
      "components_no           0\n",
      "components_no2          0\n",
      "components_o3           0\n",
      "components_so2          0\n",
      "components_pm2_5        0\n",
      "components_pm10         0\n",
      "components_nh3          0\n",
      "temperature_2m          0\n",
      "relative_humidity_2m    0\n",
      "dew_point_2m            0\n",
      "precipitation           0\n",
      "surface_pressure        0\n",
      "wind_speed_10m          0\n",
      "wind_direction_10m      0\n",
      "shortwave_radiation     0\n",
      "dtype: int64\n",
      "\n",
      "Total duplicates: 0\n",
      "\n",
      "Cleaned testing dataset saved at: ../data/cleaned/concatenated_testing_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# TESTING DATA PREPROCESSING\n",
    "# -----------------------------\n",
    "# ---------------------------\n",
    "# STEP 1: IMPORT LIBRARIES\n",
    "# ---------------------------\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 2: DEFINE PATHS\n",
    "# ---------------------------\n",
    "test_folder = \"../data/raw/testing/\"\n",
    "output_path = \"../data/cleaned/\"\n",
    "os.makedirs(output_path, exist_ok=True)  # create if not exist\n",
    "\n",
    "save_file = os.path.join(output_path, \"concatenated_testing_cleaned.csv\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 3: LIST ALL CSV FILES IN TEST FOLDER\n",
    "# ---------------------------\n",
    "test_files = [f for f in os.listdir(test_folder) if f.endswith(\".csv\")]\n",
    "print(\"Test files found:\", test_files)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 4: LOAD AND CONCATENATE ALL TEST FILES\n",
    "# ---------------------------\n",
    "df_list = []\n",
    "\n",
    "for file in test_files:\n",
    "    file_path = os.path.join(test_folder, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_list.append(df)\n",
    "\n",
    "df_test = pd.concat(df_list, ignore_index=True)\n",
    "print(\"Shape of merged test dataset:\", df_test.shape)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 5: CHECK MISSING VALUES & DUPLICATES\n",
    "# ---------------------------\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df_test.isna().sum())\n",
    "\n",
    "duplicate_count = df_test.duplicated().sum()\n",
    "print(\"\\nTotal duplicates:\", duplicate_count)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 6: CONVERT DATETIME COLUMN\n",
    "# ---------------------------\n",
    "df_test['datetime'] = pd.to_datetime(df_test['datetime'], errors='coerce')\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 7: EXTRACT TIME-BASED FEATURES\n",
    "# ---------------------------\n",
    "df_test['year'] = df_test['datetime'].dt.year\n",
    "df_test['month'] = df_test['datetime'].dt.month\n",
    "df_test['day'] = df_test['datetime'].dt.day\n",
    "df_test['hour'] = df_test['datetime'].dt.hour\n",
    "df_test['day_of_week'] = df_test['datetime'].dt.dayofweek\n",
    "df_test['is_weekend'] = df_test['day_of_week'].isin([5,6]).astype(int)\n",
    "\n",
    "# Optional: seasons\n",
    "def get_season(month):\n",
    "    if month in [12,1,2]:\n",
    "        return \"winter\"\n",
    "    elif month in [3,4,5]:\n",
    "        return \"spring\"\n",
    "    elif month in [6,7,8]:\n",
    "        return \"summer\"\n",
    "    else:\n",
    "        return \"autumn\"\n",
    "\n",
    "df_test['season'] = df_test['month'].apply(get_season)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 8: SAVE CLEANED TEST DATA\n",
    "# ---------------------------\n",
    "df_test.to_csv(save_file, index=False)\n",
    "print(\"\\nCleaned testing dataset saved at:\", save_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cae5885-3b7e-48f4-b750-14bd49dff9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>main_aqi</th>\n",
       "      <th>components_co</th>\n",
       "      <th>components_no</th>\n",
       "      <th>components_no2</th>\n",
       "      <th>components_o3</th>\n",
       "      <th>components_so2</th>\n",
       "      <th>components_pm2_5</th>\n",
       "      <th>components_pm10</th>\n",
       "      <th>components_nh3</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>wind_direction_10m</th>\n",
       "      <th>shortwave_radiation</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-07 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>747.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.63</td>\n",
       "      <td>98.71</td>\n",
       "      <td>5.78</td>\n",
       "      <td>48.03</td>\n",
       "      <td>53.20</td>\n",
       "      <td>8.99</td>\n",
       "      <td>...</td>\n",
       "      <td>15.379206</td>\n",
       "      <td>106.313930</td>\n",
       "      <td>0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-07 01:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>801.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9.94</td>\n",
       "      <td>91.55</td>\n",
       "      <td>5.30</td>\n",
       "      <td>48.77</td>\n",
       "      <td>53.33</td>\n",
       "      <td>8.87</td>\n",
       "      <td>...</td>\n",
       "      <td>7.695920</td>\n",
       "      <td>100.784256</td>\n",
       "      <td>18</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-07 02:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>988.01</td>\n",
       "      <td>0.48</td>\n",
       "      <td>20.39</td>\n",
       "      <td>79.39</td>\n",
       "      <td>6.38</td>\n",
       "      <td>49.33</td>\n",
       "      <td>53.77</td>\n",
       "      <td>10.13</td>\n",
       "      <td>...</td>\n",
       "      <td>8.396570</td>\n",
       "      <td>120.963690</td>\n",
       "      <td>107</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-07 03:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1295.09</td>\n",
       "      <td>2.88</td>\n",
       "      <td>33.24</td>\n",
       "      <td>77.25</td>\n",
       "      <td>9.18</td>\n",
       "      <td>49.95</td>\n",
       "      <td>54.29</td>\n",
       "      <td>11.27</td>\n",
       "      <td>...</td>\n",
       "      <td>5.771239</td>\n",
       "      <td>93.576260</td>\n",
       "      <td>275</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-07 04:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1121.52</td>\n",
       "      <td>2.43</td>\n",
       "      <td>23.99</td>\n",
       "      <td>120.16</td>\n",
       "      <td>15.14</td>\n",
       "      <td>42.27</td>\n",
       "      <td>46.51</td>\n",
       "      <td>9.25</td>\n",
       "      <td>...</td>\n",
       "      <td>3.096837</td>\n",
       "      <td>234.462230</td>\n",
       "      <td>446</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  main_aqi  components_co  components_no  components_no2  \\\n",
       "0 2024-01-07 00:00:00         3         747.68           0.00            7.63   \n",
       "1 2024-01-07 01:00:00         3         801.09           0.01            9.94   \n",
       "2 2024-01-07 02:00:00         3         988.01           0.48           20.39   \n",
       "3 2024-01-07 03:00:00         3        1295.09           2.88           33.24   \n",
       "4 2024-01-07 04:00:00         3        1121.52           2.43           23.99   \n",
       "\n",
       "   components_o3  components_so2  components_pm2_5  components_pm10  \\\n",
       "0          98.71            5.78             48.03            53.20   \n",
       "1          91.55            5.30             48.77            53.33   \n",
       "2          79.39            6.38             49.33            53.77   \n",
       "3          77.25            9.18             49.95            54.29   \n",
       "4         120.16           15.14             42.27            46.51   \n",
       "\n",
       "   components_nh3  ...  wind_speed_10m  wind_direction_10m  \\\n",
       "0            8.99  ...       15.379206          106.313930   \n",
       "1            8.87  ...        7.695920          100.784256   \n",
       "2           10.13  ...        8.396570          120.963690   \n",
       "3           11.27  ...        5.771239           93.576260   \n",
       "4            9.25  ...        3.096837          234.462230   \n",
       "\n",
       "   shortwave_radiation    year  month  day  hour  day_of_week  is_weekend  \\\n",
       "0                    0  2024.0    1.0  7.0   0.0          6.0           1   \n",
       "1                   18  2024.0    1.0  7.0   1.0          6.0           1   \n",
       "2                  107  2024.0    1.0  7.0   2.0          6.0           1   \n",
       "3                  275  2024.0    1.0  7.0   3.0          6.0           1   \n",
       "4                  446  2024.0    1.0  7.0   4.0          6.0           1   \n",
       "\n",
       "   season  \n",
       "0  winter  \n",
       "1  winter  \n",
       "2  winter  \n",
       "3  winter  \n",
       "4  winter  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34be5fd1-2e65-4ec8-9112-04bea1b3daa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (123134, 25)\n",
      "Testing data shape: (21792, 25)\n",
      "Features shape: (123134, 23) Target shape: (123134,)\n",
      "Prepared X_train shape: (123134, 25)\n",
      "Prepared X_test shape: (21792, 25)\n",
      "Preprocessor saved at: ../data/models/preprocessor.pkl\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Data Preparation for Modeling\n",
    "# ---------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# STEP 1: IMPORT LIBRARIES\n",
    "# ---------------------------\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 2: LOAD CLEANED TRAINING & TESTING DATA\n",
    "# ---------------------------\n",
    "train_file = \"../data/cleaned/concatenated_training_cleaned.csv\"\n",
    "test_file = \"../data/cleaned/concatenated_testing_cleaned.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_file)\n",
    "df_test = pd.read_csv(test_file)\n",
    "\n",
    "print(\"Training data shape:\", df_train.shape)\n",
    "print(\"Testing data shape:\", df_test.shape)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 3: FEATURE & TARGET SEPARATION\n",
    "# ---------------------------\n",
    "target_col = \"main_aqi\"\n",
    "\n",
    "# Drop 'datetime' from features\n",
    "feature_cols = [col for col in df_train.columns if col not in [target_col, 'datetime']]\n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train[target_col]\n",
    "\n",
    "X_test = df_test[feature_cols]\n",
    "y_test = df_test[target_col]\n",
    "\n",
    "print(\"Features shape:\", X_train.shape, \"Target shape:\", y_train.shape)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 4: ENCODING CATEGORICAL FEATURES\n",
    "# ---------------------------\n",
    "# Identify categorical columns\n",
    "categorical_cols = ['season']  # currently only 'season'\n",
    "numeric_cols = [col for col in feature_cols if col not in categorical_cols]\n",
    "\n",
    "# Column transformer: one-hot encode categorical, scale numeric\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols)  # drop first to avoid dummy trap\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit and transform training data\n",
    "X_train_prepared = preprocessor.fit_transform(X_train)\n",
    "X_test_prepared = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Prepared X_train shape:\", X_train_prepared.shape)\n",
    "print(\"Prepared X_test shape:\", X_test_prepared.shape)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 5: SAVE PREPARED ARRAYS (OPTIONAL)\n",
    "# ---------------------------\n",
    "# You can save the preprocessor for later use in model training or GUI\n",
    "import joblib\n",
    "joblib.dump(preprocessor, \"../data/models/preprocessor.pkl\")\n",
    "print(\"Preprocessor saved at: ../data/models/preprocessor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9a44b37-bcac-47e5-b8b7-8d02158ebee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season column encoded and files saved successfully in cleaned folder!\n"
     ]
    }
   ],
   "source": [
    "#Encoding Season Column\n",
    "\n",
    "# STEP: LOAD CLEANED DATA\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "train_file = \"../data/cleaned/concatenated_training_cleaned.csv\"\n",
    "test_file = \"../data/cleaned/concatenated_testing_cleaned.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_file)\n",
    "df_test = pd.read_csv(test_file)\n",
    "\n",
    "# STEP: ENCODE 'season' COLUMN\n",
    "\n",
    "season_mapping = {'spring': 0, 'summer': 1, 'autumn': 2, 'winter': 3}\n",
    "\n",
    "df_train['season'] = df_train['season'].map(season_mapping)\n",
    "df_test['season'] = df_test['season'].map(season_mapping)\n",
    "\n",
    "# STEP: SAVE UPDATED FILES\n",
    "\n",
    "df_train.to_csv(\"../data/cleaned/concatenated_training_cleaned.csv\", index=False)\n",
    "df_test.to_csv(\"../data/cleaned/concatenated_testing_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Season column encoded and files saved successfully in cleaned folder!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b2a59-7567-4226-97a4-c1aa13384ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
